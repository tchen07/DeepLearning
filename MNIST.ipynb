{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((60000, 28, 28), (60000,))\n",
      "((10000, 28, 28), (10000,))\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "\"\"\"One-hot encode y_train and y_test\"\"\"\n",
    "y_train = np.array([np.array([0]*(y)+[1]+[0]*(10-y-1)) for y in y_train])\n",
    "y_test  = np.array([np.array([0]*(y)+[1]+[0]*(10-y-1)) for y in y_test])\n",
    "\n",
    "\"\"\"Flatten Xs\"\"\"\n",
    "X_train = np.array([X.flatten() for X in X_train])\n",
    "X_test  = np.array([X.flatten() for X in X_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "classes = 10\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, input_size])\n",
    "y = tf.placeholder(\"float\", [None, classes]) # 0 through 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Multilayer perceptron\"\"\"\n",
    "# Hooray, generalized!\n",
    "\n",
    "activation = tf.nn.relu\n",
    "layers_sizes = [255, 255]\n",
    "weights = [tf.Variable(tf.random_normal([prev_layer_size, layer_size])) \\\n",
    "           for prev_layer_size, layer_size in \\\n",
    "           zip([input_size]+layers_sizes, layers_sizes+[classes])]\n",
    "\n",
    "biases = [tf.Variable(tf.random_normal([layer_size])) for layer_size in layers_sizes+[classes]]\n",
    "\n",
    "def create_layer(prev_layer, weight, bias, activation=activation):\n",
    "    layer = tf.add(tf.matmul(prev_layer, weight), bias)\n",
    "    layer = activation(layer)\n",
    "    return layer\n",
    "\n",
    "def layers():\n",
    "    layers = []\n",
    "    for ind, layer_size in enumerate(layers_sizes):\n",
    "        try:\n",
    "            last_layer = layers[-1]\n",
    "        except IndexError:\n",
    "            last_layer = X\n",
    "            print(\"raising error!\")\n",
    "        layers.append(create_layer(last_layer, weights[ind], biases[ind]))\n",
    "    layers.append(tf.add(tf.matmul(layers[-1], weights[-1]), biases[-1]))\n",
    "    print layers\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " raising error!\n",
      "[<tf.Tensor 'Relu_53:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'Relu_54:0' shape=(?, 255) dtype=float32>, <tf.Tensor 'Add_82:0' shape=(?, 10) dtype=float32>]\n",
      "Epoch  0\n",
      "Testing Acc: 0.8589\n",
      "Epoch  1\n",
      "Testing Acc: 0.8939\n",
      "Epoch  2\n",
      "Testing Acc: 0.9116\n",
      "Epoch  3\n",
      "Testing Acc: 0.9201\n",
      "Epoch  4\n",
      "Testing Acc: 0.929\n",
      "Epoch  5\n",
      "Testing Acc: 0.9305\n",
      "Epoch  6\n",
      "Testing Acc: 0.9373\n",
      "Epoch  7\n",
      "Testing Acc: 0.9367\n",
      "Epoch  8\n",
      "Testing Acc: 0.9387\n",
      "Epoch  9\n",
      "Testing Acc: 0.9382\n",
      "Epoch  10\n",
      "Testing Acc: 0.9421\n",
      "Epoch  11\n",
      "Testing Acc: 0.9441\n",
      "Epoch  12\n",
      "Testing Acc: 0.9441\n",
      "Epoch  13\n",
      "Testing Acc: 0.9454\n",
      "Epoch  14\n",
      "Testing Acc: 0.9475\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "ACC_EVERY = 1\n",
    "\n",
    "pred = layers()[-1]\n",
    "x_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(x_entropy)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for step in range(len(X_train)//BATCH_SIZE):\n",
    "        start_ind = (step*BATCH_SIZE) % len(X_train)\n",
    "        end_ind = ((step+1)*BATCH_SIZE) % len(X_train)\n",
    "        batch_X, batch_y = X_train[start_ind:end_ind], y_train[start_ind:end_ind]\n",
    "        sess.run(train_step, feed_dict={X:batch_X, y:batch_y})\n",
    "    if epoch%ACC_EVERY == 0:\n",
    "        correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print \"Epoch \", epoch\n",
    "        print \"Testing Acc:\", accuracy.eval({X: X_test, y: y_test})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
